# -*- coding: utf-8 -*-
"""Cassava_Leaf_Detection_notebooks.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gCV-jUiYZz_ptiLWJH9AaQBaOMN_8vTW

# Exploratory Data Analysis
"""

# Required imports
import os
import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
from PIL import Image
import hashlib
import os
import cv2

# Set base directory for dataset
BASE_DIR = "/kaggle/input/cassava-leaf-disease-classification"

with open("/kaggle/input/cassava-leaf-disease-classification/label_num_to_disease_map.json") as file:
    print("yes")

# Step 1: Load and inspect label map (mapping from numerical labels to disease names)
with open(os.path.join(BASE_DIR, "label_num_to_disease_map.json")) as file:
    map_classes = json.loads(file.read())
    map_classes = {int(k): v for k, v in map_classes.items()}

# Display the mapping
print("Class Mapping: ")
print(json.dumps(map_classes, indent=4))

os.listdir(os.path.join(BASE_DIR, "train_images"))

# Step 2: Load training image filenames and display the count
input_files = os.listdir(os.path.join(BASE_DIR, "train_images"))
print(f"Number of train images: {len(input_files)}")

# Step 3: Load train.csv and add a human-readable class name based on the mapping
df_train = pd.read_csv(os.path.join(BASE_DIR, "train.csv"))
df_train.head()

df_train["class_name"] = df_train["label"].map(map_classes)
df_train

df_train['class_name'].value_counts()

"""Techniques like transfer leanirng, you dont need to balance hte data. Internally model will handle. ( Pre trained model )

Scratch - then you need to do somehting about imbalance..


"""

# Step 4: Check class distribution
class_distribution = df_train['class_name'].value_counts()
# Plot the class distribution
plt.figure(figsize=(10, 6))
class_distribution.plot(kind='bar')
plt.title('Class Distribution of Cassava Leaf Disease')
plt.ylabel('Number of Images')
plt.xlabel('Disease Class')
plt.xticks(rotation=45)
plt.show()

# Alternatively, use seaborn for a countplot visualization
plt.figure(figsize=(8, 4))
sns.countplot(y="class_name", data=df_train)
plt.title('Class Distribution (Seaborn)')
plt.show()

# Step 5: Basic dataset exploration
# Show data info and summary statistics
print("Dataset Info:")
print(df_train.info())

print("\nDataset Summary Statistics:")
print(df_train.describe())

# Step 6: Check for missing values and duplicates
print(f"\nMissing values in each column:\n{df_train.isnull().sum()}")
print(f"Number of duplicate rows: {df_train.duplicated().sum()}")

"""Images -
let's check the shape of the images.

Images - 50*50 ( very small pixels )
it doesn't make any sense to upscale to 224*224 ( mess up informaiton )

images 600 * 600
resize to may be 224 224
500 * 500

images size distributin you need to tune your resize image size.
"""

path = "/kaggle/input/cassava-leaf-disease-classification/train_images/1000015157.jpg"
path2 = "1000015157.jpg"


cv2.imread(path2)

cv2.imread(path2)

# Step 7: Analyze image shapes (size dimensions) for a sample of 300 images
# Dictionary to store image shapes and their counts
img_shapes = {}
for image_name in os.listdir(os.path.join(BASE_DIR, "train_images"))[:1000]:
    image = cv2.imread(os.path.join(BASE_DIR, "train_images", image_name))
    img_shapes[image.shape] = img_shapes.get(image.shape, 0) + 1

# Display image shapes
print("\nSample Image Shapes and their Frequencies (from 1000 images):")
print(img_shapes)

"""I have my images with the size 600 * 800 * 3 ( rgb channels ) color full image."""

# Plot the image size distribution
img_shapes_df = pd.DataFrame(list(img_shapes.items()), columns=['Image Shape', 'Count'])
plt.figure(figsize=(10, 6))
img_shapes_df.sort_values(by='Count', ascending=False).plot(kind='bar', x='Image Shape', y='Count', legend=False)
plt.title('Image Shape Distribution (Sample of 300 Images)')
plt.xlabel('Image Shape')
plt.ylabel('Number of Images')
plt.xticks(rotation=45)
plt.show()

"""# Loading data
# shapes
# info
# null vlaues
# describe
# image shapes
"""

df_train.head()

# Step 8: Function to plot sample images from a specific class
def plot_images_from_class(class_id, num_images=9):
    """
    Plot sample images from a specific class in a 3x3 grid.

    Parameters:
        class_id (int): The class label to filter images.
        num_images (int): The number of images to plot.
    """
    # Filter images for the specified class
    class_images = df_train[df_train['label'] == class_id]
    num_images = min(len(class_images), num_images)  # Adjust if fewer images than requested

    plt.figure(figsize=(15, 15))  # Set figure size for better visualization
    images = class_images.sample(num_images)  # Randomly sample images

    # Plot images in a 3x3 grid
    for i, (_, row) in enumerate(images.iterrows()):
        img_path = os.path.join(BASE_DIR, "train_images", row['image_id'])
        img = Image.open(img_path)
        plt.subplot(3, 3, i + 1)
        plt.imshow(img)
        plt.title(map_classes[class_id])  # Use class name for the title
        plt.axis('off')  # Hide axis for better visualization

    plt.tight_layout()  # Adjust layout to prevent overlap
    plt.show()

"""0 1 2 3 4 5"""

plot_images_from_class(0)

# Step 9: Visualize sample images for each class (0 to 4)
for i in range(5):
    print(f"Displaying sample images for class: {map_classes[i]}")
    plot_images_from_class(i)

"""we are leaf doctors"""

# Step 10: Check image shapes for the entire dataset
df_train['image_shape'] = df_train['image_id'].apply(lambda x: cv2.imread(os.path.join(BASE_DIR, "train_images", x)).shape)

# Group by class and image shape to see if there's a pattern in image size by disease type
shape_class_dist = df_train.groupby(['class_name', 'image_shape']).size().unstack(fill_value=0)

# Plot the distribution of image sizes for each class
shape_class_dist.T.plot(kind='bar', stacked=True, figsize=(12, 6))
plt.title('Image Size Distribution by Class')
plt.xlabel('Image Shape')
plt.ylabel('Number of Images')
plt.legend(title='Class Name', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=45)
plt.show()

"""Step 1 : Analyzing the PatientÂ¶
What would be a first step that a Leaf doctor should do before anything considering the fact that his client can't speak ? The answer is simple right , analyze what's wrong by looking at the patient

But how does a doctor understands if something is wrong by just looking at it? For this as a doctor , he should know what a normal Patient/Leaf looks like and observe deviations (in pattern ,color, texture,etc) from the normal behavior to separate the healthy patients from infected ones . Now to further classify the infected ones into specific class of diseases doctor should also know how the patient/leaf condition looks like in different diseases

With these pointers in mind let's start with basic familarity

This can help you understand if certain classes are more commonly associated with specific image sizes, which might indicate that certain images were taken under different conditions or with different devices.
"""

df_train.head()

df_train['label_names'] = df_train['label'].map(map_classes)

"""# Duplicate Images"""



# Finding Duplicate Images
# Identifying Exact Duplicate Images

def get_image_hash(image_path):
    """Generate an MD5 hash for the image."""
    with open(image_path, "rb") as f:
        file_hash = hashlib.md5(f.read()).hexdigest()
    return file_hash

# Dictionary to store image hashes and their file names
image_hashes = {}

# Check for duplicate images
duplicate_images = []

for image_name in os.listdir(os.path.join(BASE_DIR, "train_images")):
    image_path = os.path.join(BASE_DIR, "train_images", image_name)
    image_hash = get_image_hash(image_path)

    if image_hash in image_hashes:
        duplicate_images.append((image_name, image_hashes[image_hash]))  # Image is a duplicate
    else:
        image_hashes[image_hash] = image_name  # Store the hash

print(f"Found {len(duplicate_images)} exact duplicate images.")
for dup in duplicate_images:
    print(f"Duplicate pair: {dup[0]} and {dup[1]}")

len(image_hashes)

"""# Model -- 1 : Let's train Base Model"""

import tensorflow as tf
from tensorflow.keras import layers, models

# Define the CNN model architecture
model = models.Sequential()

# 1st Convolutional block
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))
model.add(layers.BatchNormalization())
model.add(layers.MaxPooling2D((2, 2)))

# 2nd Convolutional block
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.BatchNormalization())
model.add(layers.MaxPooling2D((2, 2)))

# 3rd Convolutional block
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.BatchNormalization())
model.add(layers.MaxPooling2D((2, 2)))

# 4th Convolutional block
model.add(layers.Conv2D(256, (3, 3), activation='relu'))
model.add(layers.BatchNormalization())
model.add(layers.MaxPooling2D((2, 2)))

# Flatten the output to feed it into fully connected layers
model.add(layers.Flatten())

# Dense layer with 512 units
model.add(layers.Dense(512, activation='relu'))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.5))

# Output layer for classification (assuming 5 classes)
model.add(layers.Dense(5, activation='softmax'))

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',  # Assuming sparse labels (integers)
              metrics=['accuracy'])

# Model summary
model.summary()

df_train.head()

"""# Deprecated Techniques."""

images_dir = '/kaggle/input/cassava-leaf-disease-classification/train_images'

from tensorflow.keras.preprocessing.image import ImageDataGenerator
# Create an ImageDataGenerator to preprocess images
datagen = ImageDataGenerator(rescale=1./255,
                            validation_split=0.2)  # Normalize pixel values

images_dir = '/kaggle/input/cassava-leaf-disease-classification/train_images'

# Generate training and validation datasets
train_dataset = datagen.flow_from_dataframe(
    dataframe=df_train,
    directory=images_dir,
    x_col="image_id",  # Assuming the image path column is named "image_path"
    y_col="class_name",
    target_size=(224, 224),  # Adjust image size as needed
    batch_size=32,
    class_mode="categorical",
    subset="training",
    shuffle=True
)

val_dataset = datagen.flow_from_dataframe(
    dataframe=df_train,
    directory=images_dir,
    x_col="image_id",
    y_col="class_name",
    target_size=(224, 224),
    batch_size=32,
    class_mode="categorical",
    subset="validation",
    shuffle=True
)

# Train the model for 10 epochs
history = model.fit(
    train_dataset,   # Assumed preprocessed training dataset
    validation_data=val_dataset,  # Assumed preprocessed validation dataset
    epochs=1
)

# Train the model for 10 epochs
history = model.fit(
    train_dataset,   # Assumed preprocessed training dataset
    validation_data=val_dataset,  # Assumed preprocessed validation dataset
    epochs=10
)

"""# CONCULTIOSN - Model overfitting

# Complete the traiing for more epochs 20
# Do model plots
# Confusiton matrix, multi class
# Model Evaluation.

# Method 2 -- Using Tensorlfow Dataset
"""

df_train.head()

# Option 1: Using pandas' vectorized string operations
df_train['image_id'] = "/kaggle/input/cassava-leaf-disease-classification/train_images/" + df_train['image_id']
df_train.head()

from sklearn.model_selection import train_test_split

# Define the validation split ratio
VALIDATION_SPLIT = 0.2  # 20% for validation

# Perform stratified split to maintain class distribution
train_df, val_df = train_test_split(
    df_train,
    test_size=VALIDATION_SPLIT,
    stratify=df_train['label'],
    random_state=42
)

print(f"Training samples: {len(train_df)}")
print(f"Validation samples: {len(val_df)}")

print("Training class distribution:")
print(train_df['label'].value_counts())

print("\nValidation class distribution:")
print(val_df['label'].value_counts())

# Image dimensions
IMG_HEIGHT = 224
IMG_WIDTH = 224
CHANNELS = 3

# Batch size
BATCH_SIZE = 32

# Buffer size for shuffling
BUFFER_SIZE = 1000

# AUTOTUNE for performance optimization
AUTOTUNE = tf.data.AUTOTUNE

def process_image(file_path, label):
    # Read the image from disk
    image = tf.io.read_file(file_path)

    # Decode the image (assuming JPEG format)
    image = tf.image.decode_jpeg(image, channels=CHANNELS)

    # Resize the image
    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])

    # Normalize pixel values to [0,1]
    image = image / 255.0

    return image, label

df_train.head()

# Create TensorFlow Dataset from training DataFrame
train_ds = tf.data.Dataset.from_tensor_slices((train_df['image_id'].values, train_df['label'].values))

# Map the processing function to each (image, label) pair
train_ds = train_ds.map(process_image, num_parallel_calls=AUTOTUNE)

# Data Augmentation (optional but recommended)
data_augmentation = tf.keras.Sequential([
    layers.RandomFlip('horizontal'),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.18),
    layers.RandomContrast(0.2),
])

def augment(image, label):
    image = data_augmentation(image)
    return image, label

train_ds = train_ds.map(augment, num_parallel_calls=AUTOTUNE)

# Shuffle, batch, and prefetch
train_ds = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(AUTOTUNE)

# Create TensorFlow Dataset from validation DataFrame
val_ds = tf.data.Dataset.from_tensor_slices((val_df['image_id'].values, val_df['label'].values))

# Map the processing function
val_ds = val_ds.map(process_image, num_parallel_calls=AUTOTUNE)

# Batch and prefetch
val_ds = val_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)

from tensorflow.keras import regularizers

num_classes = 5
# Define the CNN model architecture
def create_cnn_model(input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS), num_classes=5):
    model = models.Sequential([
        # 1st Convolutional block
        layers.Input(shape=input_shape),
        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),

        # 2nd Convolutional block
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),

        # 3rd Convolutional block
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),

        # 4th Convolutional block
        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),

        # Flatten and Dense layers
        layers.Flatten(),
        layers.Dense(512, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.5),

        # Output layer
        layers.Dense(5, activation='softmax')
    ])

    return model

# Instantiate the model
model = create_cnn_model(input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS), num_classes=num_classes)

# Display the model architecture
model.summary()

# Compile the model
model.compile(
    optimizer='adam',  # You can experiment with different optimizers
    loss='categorical_crossentropy',  # Suitable for integer-encoded labels
    metrics=['accuracy']
)

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

# Early stopping to prevent overfitting
early_stop = EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True,
    verbose=1
)

# Model checkpoint to save the best model
checkpoint = ModelCheckpoint(
    'best_cnn_model.keras',
    monitor='val_accuracy',
    save_best_only=True,
    verbose=1
)

# Reduce learning rate when a metric has stopped improving
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.2,
    patience=3,
    verbose=1,
    min_lr=1e-6
)

# Combine callbacks
callbacks = [early_stop, checkpoint, reduce_lr]

val_dataset

# Train the model for 10 epochs
history = model.fit(
    train_dataset,   # Assumed preprocessed training dataset
    validation_data=val_dataset,  # Assumed preprocessed validation dataset
    epochs=1
)

# Define the number of epochs
EPOCHS = 10  # Adjust based on your requirements

# Train the model
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    callbacks=callbacks
)

# Step 14: Evaluate the Model
val_loss, val_accuracy = model.evaluate(val_ds)
print(f"\nValidation Loss: {val_loss:.4f}")
print(f"Validation Accuracy: {val_accuracy:.4f}")

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs_range = range(len(acc))

# Plot Accuracy
plt.figure(figsize=(14, 6))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')

plt.show()

"""# Visualising the augmentations"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define your data augmentation generator
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Example usage on one image
from tensorflow.keras.preprocessing import image

img = image.load_img('/kaggle/input/cassava-leaf-disease-classification/train_images/1001320321.jpg',
                     target_size=(224, 224))
x = image.img_to_array(img)
x = x.reshape((1,) + x.shape)

# Generate 5 augmented images
i = 0
for batch in datagen.flow(x, batch_size=1):
    plt.figure(i)
    imgplot = plt.imshow(image.array_to_img(batch[0]))
    i += 1
    if i % 5 == 0:
        break
plt.show()

"""# Understanding class weights"""

# Compute class weights
from sklearn.utils import class_weight
import numpy as np

class_weights = class_weight.compute_class_weight(
    'balanced',
    classes=np.unique(df_train['label']),
    y=df_train['label']
)
class_weights = dict(enumerate(class_weights))
class_weights

model.fit(class_weights = class_weights )

"""# Implementing Focal Loss"""

focal_loss = tfa.losses.SparseCategoricalFocalCrossentropy(
    from_logits=False,  # Since the model outputs probabilities with softmax
    alpha=class_weights,  # Class weights computed earlier
    gamma=2.0  # Focusing parameter
)

model.compile(
    optimizer='adam',
    loss=focal_loss,
    metrics=['accuracy']
)

history = model.fit(
                    train_ds,
                    validation_data=val_ds,
                    epochs=10,
                    callbacks=callbacks
                   )

# Step 14: Evaluate the Model
val_loss, val_accuracy = model.evaluate(val_ds)
print(f"\nValidation Loss: {val_loss:.4f}")
print(f"Validation Accuracy: {val_accuracy:.4f}")

# Step 15: Save the Model
model.save('cnn_cassava_leaf_disease_focal_loss.keras')
print("\nModel saved successfully!")

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs_range = range(len(acc))

# Plot Accuracy
plt.figure(figsize=(14, 6))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')

plt.show()

"""# Implementing Transfer Learning RESNET

# Home work fine tuning.
# Model training, plotting, evalution, confusion matirix.
"""



from tensorflow.keras.applications import ResNet50

# Effecient net

# Load the ResNet50 model without the top classification layers
base_model = ResNet50(
    weights='imagenet',
    include_top=False,
    input_shape=(224, 224, 3)
)

# Freeze the base model
base_model.trainable = False

# Create a new model on top
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(256, activation='relu'),
    layers.BatchNormalization(),
    layers.Dense(512, activation='relu'),
    layers.BatchNormalization(),
    layers.Dropout(0.5),
    layers.Dense(5, activation='softmax')
])

# Compile with Focal Loss
model.compile(
    optimizer='adam',
    loss='categorial_cross_entropy',
    metrics=['accuracy']
)

# Model summary
model.summary()

"""# Transfer Leanring Effecient Net"""

!pip uninstall tensorflow_addons

# Step 1: Import Necessary Libraries
import os
import json
from collections import Counter

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models, regularizers
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
# import tensorflow_addons as tfa

from sklearn.model_selection import train_test_split
from sklearn.utils import class_weight


import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import RMSprop, Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.applications import EfficientNetB3

# Step 2: Define Paths
work_dir = '../input/cassava-leaf-disease-classification/'  # Update if necessary
train_path = os.path.join(work_dir, 'train_images')  # Path to training images
train_csv_path = os.path.join(work_dir, 'train.csv')  # Path to train.csv
label_map_path = os.path.join(work_dir, 'label_num_to_disease_map.json')  # Path to label mapping JSON

# a. Load Train Data
data = pd.read_csv(train_csv_path)
print("Initial DataFrame:")
print(data.head())

# Check label frequencies
print("\nLabel Frequencies:")
print(Counter(data['label']))

# b. Load Label Mapping
with open(label_map_path, 'r') as f:
    real_labels = json.load(f)

# Convert string keys to integers
real_labels = {int(k): v for k, v in real_labels.items()}

# Map label numbers to class names
data['class_name'] = data['label'].map(real_labels)
print("\nDataFrame with 'class_name':")
print(data.head())

# Step 4: Compute Class Weights
labels = data['label'].values  # Integer-encoded labels

# Compute class weights
class_weights_array = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.unique(labels),
    y=labels
)

# Create a dictionary mapping class indices to weights
class_weights_dict = {i: weight for i, weight in enumerate(class_weights_array)}
print("\nClass Weights:")
print(class_weights_dict)

# Step 5: Define ImageDataGenerators
IMG_SIZE = 224
TARGET_SIZE = (IMG_SIZE, IMG_SIZE)
NUM_CLASSES = 5  # Update based on actual number of classes
BATCH_SIZE = 15

datagen_train = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,  # EfficientNet preprocessing
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    vertical_flip=True,
    fill_mode='nearest'
)

# ImageDataGenerator for validation (only normalization)
datagen_val = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input  # EfficientNet preprocessing
)

"""# Effecient net uses upscaling metod. 512 * 512"""

train_df, val_df = train_test_split(
    data,
    test_size=0.05,  # 5% for validation
    random_state=42,
    stratify=data['class_name']
)
print(f"\nNumber of training samples: {len(train_df)}")
print(f"Number of validation samples: {len(val_df)}")

train_set = datagen_train.flow_from_dataframe(train_df,
                             directory = train_path,
                             seed=42,
                             x_col = 'image_id',
                             y_col = 'class_name',
                             target_size = TARGET_SIZE,
                             #color_mode="rgb",
                             class_mode = 'categorical',
                             interpolation = 'nearest',
                             shuffle = True,
                             batch_size = BATCH_SIZE)

val_set = datagen_val.flow_from_dataframe(val_df,
                             directory = train_path,
                             seed=42,
                             x_col = 'image_id',
                             y_col = 'class_name',
                             target_size = TARGET_SIZE,
                             #color_mode="rgb",
                             class_mode = 'categorical',
                             interpolation = 'nearest',
                             shuffle = True,
                             batch_size = BATCH_SIZE)

base_model = EfficientNetB3(input_shape=(224, 224, 3), include_top=False,
                                weights='imagenet', drop_connect_rate=0.6)

base_model.summary()

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.applications import EfficientNetB3

# Set up the model
model = Sequential()

# Add an input layer
model.add(tf.keras.Input(shape=(224, 224, 3)))

# Add EfficientNetB3 base model
base_model = EfficientNetB3(include_top=False, weights='imagenet', drop_connect_rate=0.6)
model.add(base_model)

# Now the model is built, you can call summary
model.summary()

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.applications import EfficientNetB3

def create_model():

    model = Sequential()
    # Add an input layer
    model.add(tf.keras.Input(shape=(224, 224, 3)))

    # Initialize EfficientNetB3 with input_shape explicitly defined
    base_model = EfficientNetB3(input_shape=(224, 224, 3), include_top=False,
                                weights='imagenet', drop_connect_rate=0.6)

    # Freeze layers (except last 40 layers)
    for layer in base_model.layers[:-40]:
        layer.trainable = False

    # Add the base model
    model.add(base_model)

    # Add global average pooling layer
    model.add(GlobalAveragePooling2D())

    # Add Dense layer with regularization
    model.add(Dense(256, activation='relu',
                    bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.001)))

    # Add Dropout layer
    model.add(Dropout(0.5))

    # Add output Dense layer for classification (5 classes)
    model.add(Dense(5, activation='softmax'))

    return model

# Create and summarize the model
leaf_model = create_model()
leaf_model.summary()

EPOCHS = 50
STEP_SIZE_TRAIN = train_set.n//train_set.batch_size
STEP_SIZE_VALID = val_set.n//val_set.batch_size

def Model_fit():

    #leaf_model = None

    leaf_model = create_model()

    '''Compiling the model'''

    loss = tf.keras.losses.CategoricalCrossentropy(from_logits = False,
                                                   label_smoothing=0.0001,
                                                   name='categorical_crossentropy' )

    leaf_model.compile(optimizer = Adam(learning_rate = 1e-3),
                        loss = loss, #'categorical_crossentropy'
                        metrics = ['categorical_accuracy']) #'acc'

    # Stop training when the val_loss has stopped decreasing for 3 epochs.
    es = EarlyStopping(monitor='val_loss', mode='min', patience=3,
                       restore_best_weights=True, verbose=1)

    # Save the model with the minimum validation loss
    checkpoint_cb = ModelCheckpoint("Cassava_best_model.keras",
                                    save_best_only=True,
                                    monitor = 'val_loss',
                                    mode='min')
    # reduce learning rate
    reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',
                                  factor = 0.2,
                                  patience = 2,
                                  min_lr = 1e-6,
                                  mode = 'min',
                                  verbose = 1)

    history = leaf_model.fit(train_set,
                             validation_data = val_set,
                             epochs= EPOCHS,
                             batch_size = BATCH_SIZE,
                             # class_weight = d_class_weights,
                             steps_per_epoch = STEP_SIZE_TRAIN,
                             validation_steps = STEP_SIZE_VALID,
                             callbacks=[es, checkpoint_cb, reduce_lr])

    leaf_model.save('Cassava_model'+'.keras')

    return history

results = Model_fit()

print('Train_Cat-Acc: ', max(results.history['categorical_accuracy']))
print('Val_Cat-Acc: ', max(results.history['val_categorical_accuracy']))

def Train_Val_Plot(acc,val_acc,loss,val_loss):

    fig, (ax1, ax2) = plt.subplots(1,2, figsize= (15,10))
    fig.suptitle(" MODEL'S METRICS VISUALIZATION ", fontsize=20)

    ax1.plot(range(1, len(acc) + 1), acc)
    ax1.plot(range(1, len(val_acc) + 1), val_acc)
    ax1.set_title('History of Accuracy', fontsize=15)
    ax1.set_xlabel('Epochs', fontsize=15)
    ax1.set_ylabel('Accuracy', fontsize=15)
    ax1.legend(['training', 'validation'])


    ax2.plot(range(1, len(loss) + 1), loss)
    ax2.plot(range(1, len(val_loss) + 1), val_loss)
    ax2.set_title('History of Loss', fontsize=15)
    ax2.set_xlabel('Epochs', fontsize=15)
    ax2.set_ylabel('Loss', fontsize=15)
    ax2.legend(['training', 'validation'])
    plt.show()


Train_Val_Plot(results.history['categorical_accuracy'],results.history['val_categorical_accuracy'],
               results.history['loss'],results.history['val_loss'])

# EVALUATING THE MODEL

import keras

final_model = keras.models.load_model('Cassava_best_model.keras')

"""# Test Time Augmentaiton"""

TEST_DIR = '../input/cassava-leaf-disease-classification/test_images/'
test_images = os.listdir(TEST_DIR)
datagen = ImageDataGenerator(horizontal_flip=True)


def pred(images):
    for image in test_images:
        img = Image.open(TEST_DIR + image)
        img = img.resize(size)
        samples = np.expand_dims(img, axis=0)
        it = datagen.flow(samples, batch_size=10)
        yhats = final_model.predict_generator(it, steps=10, verbose=0)
        summed = np.sum(yhats, axis=0)
    return np.argmax(summed)

predictions = pred(test_images)